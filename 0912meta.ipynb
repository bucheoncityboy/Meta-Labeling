{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f2ad8a-b2c6-4ae7-92c5-173d69d007d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77eb4721-e39c-4d5d-bf61-0ec59bd01a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/Users/youngjaekim/Desktop/퀀트랩/lastsnp.csv' 파일 로딩 성공!\n",
      "초기 데이터 형태: (556129, 8)\n",
      "\n",
      "373개 종목의 메타데이터(섹터, 시가총액)를 yfinance에서 가져옵니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata: 100%|██████████████████████| 373/373 [03:56<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "메타데이터 병합 완료!\n",
      "최종 데이터 형태: (556033, 10)\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/jaewonkim/Desktop/퀀트랩/lastsnp.csv'\n",
    "full_df = pd.read_csv(file_path, parse_dates=['Date'])\n",
    "\n",
    "print(f\"'{file_path}' 파일 로딩 성공!\")\n",
    "print(f\"초기 데이터 형태: {full_df.shape}\")\n",
    "\n",
    "tickers = full_df['Ticker'].unique().tolist()\n",
    "print(f\"\\n{len(tickers)}개 종목의 메타데이터(섹터, 시가총액)를 yfinance에서 가져옵니다...\")\n",
    "metadata = {}\n",
    "for ticker in tqdm(tickers, desc=\"Fetching Metadata\"):\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        metadata[ticker] = {\n",
    "            'Sector': info.get('sector', 'N/A'),\n",
    "            'Market_Cap': info.get('marketCap', np.nan)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        metadata[ticker] = {'Sector': 'N/A', 'Market_Cap': np.nan}\n",
    "\n",
    "metadata_df = pd.DataFrame.from_dict(metadata, orient='index').reset_index().rename(columns={'index': 'Ticker'})\n",
    "full_df = pd.merge(full_df, metadata_df, on='Ticker', how='left')\n",
    "\n",
    "full_df.dropna(subset=['Sector', 'Market_Cap'], inplace=True)\n",
    "full_df = full_df[full_df['Sector'] != 'N/A']\n",
    "\n",
    "print(\"\\n메타데이터 병합 완료!\")\n",
    "print(f\"최종 데이터 형태: {full_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103d8449-44b1-40af-ab68-876e1b4080e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA 피처 45개를 생성합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 45 EMA Features: 100%|███████████████| 45/45 [00:17<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "피처 엔지니어링 완료.\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df.sort_values(by=['Ticker', 'Date'], inplace=True)\n",
    "    \n",
    "    # 논문 정의에 따른 '일중 수익률' 계산: (종가 / 시가) - 1\n",
    "    df['Intraday_Return'] = (df['Close'] / df['Open']) - 1\n",
    "    \n",
    "    # 섹터별 평균 일중 수익률 및 비정상 수익률 (Abnormal Return)\n",
    "    sector_return = df.groupby(['Date', 'Sector'])['Intraday_Return'].transform('mean')\n",
    "    df['Abnormal_Return'] = df['Intraday_Return'] - sector_return\n",
    "    \n",
    "    # EMA 피처 (45개)\n",
    "    print(\"EMA 피처 45개를 생성합니다...\")\n",
    "    short_windows = [1, 3, 5, 7, 9, 11, 13, 15, 17]\n",
    "    long_windows = [3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "    combinations = []\n",
    "    for s in short_windows:\n",
    "        for l in long_windows:\n",
    "            if l >= s + 2:\n",
    "                combinations.append((s, l))\n",
    "    for s, l in tqdm(combinations, desc=\"Generating 45 EMA Features\"):\n",
    "        ema_short = df.groupby('Ticker')['Close'].transform(lambda x: ta.ema(x, length=s))\n",
    "        ema_long = df.groupby('Ticker')['Close'].transform(lambda x: ta.ema(x, length=l))\n",
    "        df[f'EMA_{l}_{s}'] = (ema_short - ema_long) / ema_long\n",
    "\n",
    "    # VIX 피처 (원본)\n",
    "    df['VIX_20'] = ta.ema(df['VIX_Close'], length=20)\n",
    "    df['VIX_100'] = ta.ema(df['VIX_Close'], length=100)\n",
    "    df['VIX_Feature'] = df['VIX_20'] - df['VIX_100']\n",
    "\n",
    "    # 개별 주식 변동성 피처\n",
    "    df['Stock_Vol_5'] = df.groupby('Ticker')['Abnormal_Return'].transform(lambda x: x.ewm(span=5).std())\n",
    "    df['Stock_Vol_20'] = df.groupby('Ticker')['Abnormal_Return'].transform(lambda x: x.ewm(span=20).std())\n",
    "    df['Stock_Unique_Volatility'] = df['Stock_Vol_5'] - df['Stock_Vol_20']\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "processed_df = feature_engineering(full_df.copy())\n",
    "print(\"\\n피처 엔지니어링 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f151ae0d-d9c3-4a63-937a-890a45a40483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Binning EMA features: 100%|█████████████████████| 45/45 [24:31<00:00, 32.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 데이터: (6487225, 65), 테스트 데이터: (1260336, 65)\n"
     ]
    }
   ],
   "source": [
    "# EMA 피처 이산화 (섹터별)\n",
    "ema_cols = [col for col in processed_df.columns if 'EMA_' in col]\n",
    "for col in tqdm(ema_cols, desc=\"Binning EMA features\"):\n",
    "    processed_df[col] = processed_df.groupby(['Date', 'Sector'])[col].transform(\n",
    "        lambda x: pd.qcut(x, 5, labels=False, duplicates='drop')\n",
    "    )\n",
    "\n",
    "# VIX 피처 이산화 (30일 롤링 윈도우)\n",
    "vix_daily = processed_df[['Date', 'VIX_Feature']].drop_duplicates().set_index('Date').sort_index()\n",
    "def assign_rolling_quintile(series):\n",
    "    try:\n",
    "        bins = pd.qcut(series, 5, retbins=True, duplicates='drop')[1]\n",
    "        return pd.cut([series.iloc[-1]], bins=bins, labels=False, include_lowest=True)[0]\n",
    "    except (ValueError, IndexError): return np.nan\n",
    "vix_daily['VIX_quintile'] = vix_daily['VIX_Feature'].rolling(window=30, min_periods=5).apply(assign_rolling_quintile, raw=False)\n",
    "processed_df = pd.merge(processed_df, vix_daily[['VIX_quintile']], on='Date', how='left')\n",
    "\n",
    "# 기타 피처 이산화 (시가총액, 고유 변동성)\n",
    "for col in ['Market_Cap', 'Stock_Unique_Volatility']:\n",
    "     processed_df[col] = processed_df.groupby('Date')[col].transform(\n",
    "        lambda x: pd.qcut(x, 5, labels=False, duplicates='drop')\n",
    "    )\n",
    "\n",
    "# 타겟 변수 생성 및 데이터 분할\n",
    "processed_df.dropna(inplace=True)\n",
    "processed_df['Target'] = (processed_df['Abnormal_Return'] > 0).astype(int)\n",
    "\n",
    "train_df = processed_df[processed_df['Date'] < '2020-01-01'].copy()\n",
    "test_df = processed_df[processed_df['Date'] >= '2020-01-01'].copy()\n",
    "print(f\"\\n학습 데이터: {train_df.shape}, 테스트 데이터: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9819a6-dda9-467b-9333-698271396612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSFI Feature Selection: 100%|████████████████| 45/45 [1:43:22<00:00, 137.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "상위 10개 피처: ['EMA_3_1', 'EMA_5_1', 'EMA_7_1', 'EMA_9_1', 'EMA_11_1', 'EMA_13_1', 'EMA_15_1', 'EMA_5_3', 'EMA_17_1', 'EMA_19_1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 성능 이슈로 n_splits=10-->5, n_estimators=500-->50\n",
    "def ssfi_feature_selection(df, features):\n",
    "    sample_weights = np.abs(df['Abnormal_Return'])\n",
    "    y = df['Target']\n",
    "    cv = KFold(n_splits=5, shuffle=False)\n",
    "    feature_scores = {}\n",
    "    for feature in tqdm(features, desc=\"SSFI Feature Selection\"):\n",
    "        X = df[[feature]].astype(int)\n",
    "        scores = []\n",
    "        for train_idx, val_idx in cv.split(X):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            sw_train, sw_val = sample_weights.iloc[train_idx], sample_weights.iloc[val_idx]\n",
    "            \n",
    "            model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train, y_train, sample_weight=sw_train)\n",
    "            preds = model.predict(X_val)\n",
    "            scores.append(matthews_corrcoef(y_val, preds, sample_weight=sw_val))\n",
    "        feature_scores[feature] = np.mean(scores)\n",
    "    return sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "ema_features = [col for col in train_df.columns if 'EMA_' in col]\n",
    "top_10_features = ssfi_feature_selection(train_df, ema_features)\n",
    "selected_features = [f[0] for f in top_10_features]\n",
    "print(\"\\n상위 10개 피처:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65887f2b-1bb1-4b80-8171-4f2d8977e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector 정수 인코딩\n",
    "train_df['Sector_encoded'] = pd.factorize(train_df['Sector'])[0]\n",
    "test_df['Sector_encoded'] = pd.factorize(test_df['Sector'])[0]\n",
    "\n",
    "# 피처셋 정의\n",
    "additional_features = ['Sector_encoded', 'Market_Cap', 'VIX_quintile', 'Stock_Unique_Volatility']\n",
    "train_features = train_df[selected_features + additional_features]\n",
    "test_features = test_df[selected_features + additional_features]\n",
    "\n",
    "# 학습/테스트 데이터 컬럼 맞춤\n",
    "train_labels, test_labels = train_features.align(test_features, join='inner', axis=1, fill_value=0)\n",
    "\n",
    "# 최종 데이터셋 준비\n",
    "X_train_primary = train_labels[selected_features]\n",
    "X_test_primary = test_labels[selected_features]\n",
    "X_train_add = train_labels[[col for col in additional_features if col in train_labels.columns]]\n",
    "X_test_add = test_labels[[col for col in additional_features if col in test_labels.columns]]\n",
    "y_train = train_df.loc[train_labels.index, 'Target']\n",
    "y_test = test_df.loc[test_labels.index, 'Target']\n",
    "sw_train = np.abs(train_df.loc[train_labels.index, 'Abnormal_Return'])\n",
    "sw_test = np.abs(test_df.loc[test_labels.index, 'Abnormal_Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a064ec3-a205-4290-b68e-0b3c8fb5d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Model 학습 중...\n",
      "Meta Model 1 학습 중...\n",
      "Meta Model 2 학습 중...\n",
      "Non-Meta Model 학습 중...\n",
      "\n",
      "모든 모델 학습 완료.\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 정의\n",
    "rf_params = {\n",
    "    'n_estimators': 200, \n",
    "    'max_features': 0.5, \n",
    "    'min_weight_fraction_leaf': 0.001,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# 1. Primary Model 학습\n",
    "print(\"Primary Model 학습 중...\")\n",
    "primary_model = RandomForestClassifier(**rf_params)\n",
    "primary_model.fit(X_train_primary, y_train, sample_weight=sw_train)\n",
    "primary_preds_train = primary_model.predict(X_train_primary)\n",
    "\n",
    "# Meta Target 생성\n",
    "meta_target_train = (primary_preds_train == y_train).astype(int)\n",
    "\n",
    "# 2. Meta Model 1 (Regimes Only) 학습\n",
    "print(\"Meta Model 1 학습 중...\")\n",
    "meta_model_1 = RandomForestClassifier(**rf_params)\n",
    "meta_model_1.fit(X_train_add, meta_target_train, sample_weight=sw_train)\n",
    "\n",
    "# 3. Meta Model 2 (Regimes + X) 학습\n",
    "print(\"Meta Model 2 학습 중...\")\n",
    "meta_model_2 = RandomForestClassifier(**rf_params)\n",
    "meta_model_2.fit(train_labels, meta_target_train, sample_weight=sw_train)\n",
    "\n",
    "# 4. Non-Meta Model 학습\n",
    "print(\"Non-Meta Model 학습 중...\")\n",
    "non_meta_model = RandomForestClassifier(**rf_params)\n",
    "non_meta_model.fit(train_labels, y_train, sample_weight=sw_train)\n",
    "\n",
    "print(\"\\n모든 모델 학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e928d52e-7701-4359-9d8c-ca0ab9d6be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OOS 평가 결과 ---\n",
      "\n",
      "Primary Model 결과:\n",
      " Matthews       0.767809\n",
      "Accuracy       0.883777\n",
      "Precision 1    0.874151\n",
      "Precision 0    0.893912\n",
      "dtype: float64\n",
      "\n",
      "Non-Meta Model 결과:\n",
      " Matthews       0.782201\n",
      "Accuracy       0.891004\n",
      "Precision 1    0.882483\n",
      "Precision 0    0.899912\n",
      "dtype: float64\n",
      "\n",
      "Meta Model 1 (필터링 후) 결과:\n",
      " Matthews       0.767809\n",
      "Accuracy       0.883777\n",
      "Precision 1    0.874151\n",
      "Precision 0    0.893912\n",
      "dtype: float64\n",
      "\n",
      "Meta Model 2 (필터링 후) 결과:\n",
      " Matthews       0.786959\n",
      "Accuracy       0.893332\n",
      "Precision 1    0.882827\n",
      "Precision 0    0.904426\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, sample_weight):\n",
    "    if len(y_true) == 0: return {}\n",
    "    mcc = matthews_corrcoef(y_true, y_pred, sample_weight=sample_weight)\n",
    "    accuracy = accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n",
    "    precision_1 = precision_score(y_true, y_pred, sample_weight=sample_weight, pos_label=1, zero_division=0)\n",
    "    precision_0 = precision_score(y_true, y_pred, sample_weight=sample_weight, pos_label=0, zero_division=0)\n",
    "    return {'Matthews': mcc, 'Accuracy': accuracy, 'Precision 1': precision_1, 'Precision 0': precision_0}\n",
    "\n",
    "print(\"--- OOS 평가 결과 ---\")\n",
    "primary_preds_test = primary_model.predict(X_test_primary)\n",
    "primary_results = evaluate_model(y_test, primary_preds_test, sw_test)\n",
    "print(\"\\nPrimary Model 결과:\\n\", pd.Series(primary_results))\n",
    "\n",
    "non_meta_preds_test = non_meta_model.predict(test_labels)\n",
    "non_meta_results = evaluate_model(y_test, non_meta_preds_test, sw_test)\n",
    "print(\"\\nNon-Meta Model 결과:\\n\", pd.Series(non_meta_results))\n",
    "\n",
    "meta_preds_1 = meta_model_1.predict(X_test_add)\n",
    "meta_preds_2 = meta_model_2.predict(test_labels)\n",
    "\n",
    "# Meta Model 1\n",
    "y_test_meta1 = y_test[meta_preds_1 == 1]\n",
    "primary_preds_meta1 = pd.Series(primary_preds_test, index=y_test.index)[meta_preds_1 == 1]\n",
    "sw_test_meta1 = sw_test[meta_preds_1 == 1]\n",
    "meta1_results = evaluate_model(y_test_meta1, primary_preds_meta1, sw_test_meta1)\n",
    "print(\"\\nMeta Model 1 (필터링 후) 결과:\\n\", pd.Series(meta1_results))\n",
    "\n",
    "# Meta Model 2\n",
    "y_test_meta2 = y_test[meta_preds_2 == 1]\n",
    "primary_preds_meta2 = pd.Series(primary_preds_test, index=y_test.index)[meta_preds_2 == 1]\n",
    "sw_test_meta2 = sw_test[meta_preds_2 == 1]\n",
    "meta2_results = evaluate_model(y_test_meta2, primary_preds_meta2, sw_test_meta2)\n",
    "print(\"\\nMeta Model 2 (필터링 후) 결과:\\n\", pd.Series(meta2_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3269405-57d6-4346-b8b5-b00662ea612c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
